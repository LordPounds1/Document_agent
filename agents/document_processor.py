import logging
import json
import re
import os
import tempfile
from typing import Dict, Optional
from docx import Document
from pathlib import Path

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
try:
    import textract
except ImportError:
    textract = None

logger = logging.getLogger(__name__)

class DocumentProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.llm_client = None
        self.model_path = model_path
        
        if model_path:
            self._init_local_model(model_path)

    def _init_local_model(self, model_path: str):
        try:
            from llama_cpp import Llama
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {model_path}")
            
            # –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            # n_ctx=0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –º–æ–¥–µ–ª–∏ (–æ–±—ã—á–Ω–æ 32k –¥–ª—è Mistral v0.3),
            # –Ω–æ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å—Ç–∞–≤–∏–º —è–≤–Ω—ã–µ 16384 (—Ö–≤–∞—Ç–∏—Ç –Ω–∞ ~50 —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–µ–∫—Å—Ç–∞)
            self.llm_client = Llama(
                model_path=model_path,
                n_ctx=16384,          # –ë—ã–ª–æ 4096 -> —Å—Ç–∞–ª–æ 16384
                n_gpu_layers=35,      # –ï—Å–ª–∏ –ø–∞–¥–∞–µ—Ç –ø–æ –ø–∞–º—è—Ç–∏ GPU, —É–º–µ–Ω—å—à–∏ —ç—Ç–æ —á–∏—Å–ª–æ (–Ω–∞–ø—Ä. –¥–æ 20)
                verbose=False
            )
            logger.info(f"[OK] –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (Context: 16k)")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.llm_client = None

    def extract_text_from_attachments(self, attachments: list) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤–ª–æ–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ .doc, .docx, .pdf)"""
        texts = []

        for att in attachments or []:
            filename = att.get("filename", "")
            file_data = att.get("data")
            
            if not filename or not file_data:
                continue

            suffix = Path(filename).suffix.lower()
            if suffix not in ['.doc', '.docx', '.pdf']:
                continue

            try:
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                    tmp_file.write(file_data)
                    tmp_path = tmp_file.name
                
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}")
                extracted_text = ""

                # .DOCX
                if suffix == ".docx":
                    try:
                        doc = Document(tmp_path)
                        extracted_text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è .docx {filename}: {e}")

                # .DOC
                elif suffix == ".doc":
                    if textract:
                        try:
                            extracted_text = textract.process(tmp_path).decode('utf-8')
                        except: pass
                    
                    if not extracted_text:
                        # –ë–∏–Ω–∞—Ä–Ω—ã–π —Ñ–æ–ª–ª–±—ç–∫
                        with open(tmp_path, 'rb') as f:
                            binary = f.read()
                            # –§–∏–ª—å—Ç—Ä: –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É (C0-FF) –∏ ASCII
                            text = ''.join(chr(b) if (0xC0 <= b <= 0xFF) or (32 <= b < 127) or b in [10, 13] else ' ' for b in binary)
                            extracted_text = re.sub(r'\s+', ' ', text).strip()

                # .PDF
                elif suffix == ".pdf":
                    try:
                        import PyPDF2
                        with open(tmp_path, 'rb') as pdf_file:
                            reader = PyPDF2.PdfReader(pdf_file)
                            extracted_text = ""
                            for page_num in range(len(reader.pages)):
                                page = reader.pages[page_num]
                                extracted_text += page.extract_text() + "\n"
                            extracted_text = extracted_text.strip()
                    except Exception as e:
                        logger.debug(f"PyPDF2 –Ω–µ –ø–æ–º–æ–≥ —Å {filename}: {e}")
                        try:
                            import pdfplumber
                            with pdfplumber.open(tmp_path) as pdf:
                                extracted_text = ""
                                for page in pdf.pages:
                                    extracted_text += page.extract_text() or ""
                                    extracted_text += "\n"
                            extracted_text = extracted_text.strip()
                        except Exception as e2:
                            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {filename}: {e2}")

                if extracted_text and len(extracted_text) > 50:
                    texts.append(f"--- –î–û–ö–£–ú–ï–ù–¢: {filename} ---\n{extracted_text}")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {filename}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ {filename}: {e}")
            finally:
                if 'tmp_path' in locals() and os.path.exists(tmp_path):
                    try: os.unlink(tmp_path)
                    except: pass

        return "\n\n".join(texts)

    def extract_info(self, email_text: str, email_subject: str, attachments: list = None) -> Dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM"""
        
        contract_text = self.extract_text_from_attachments(attachments)

        if contract_text.strip():
            logger.info("üìÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM...")
            
            # –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –£–º–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ (Head + Tail)
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 7000 —Å–∏–º–≤–æ–ª–æ–≤ (–ü—Ä–µ–∞–º–±—É–ª–∞, –ü—Ä–µ–¥–º–µ—Ç) –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3000 (–†–µ–∫–≤–∏–∑–∏—Ç—ã, –ü–æ–¥–ø–∏—Å–∏)
            if len(contract_text) > 12000:
                full_text = contract_text[:8000] + "\n\n...[–ü–†–û–ü–£–°–ö –°–¢–ê–ù–î–ê–†–¢–ù–´–• –£–°–õ–û–í–ò–ô]...\n\n" + contract_text[-4000:]
                logger.info(f"‚úÇÔ∏è –¢–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω: {len(contract_text)} -> {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                full_text = contract_text
        else:
            logger.warning("[WARN] –¢–µ–∫—Å—Ç –≤–ª–æ–∂–µ–Ω–∏–π –ø—É—Å—Ç! –ò—Å–ø–æ–ª—å–∑—É—é —Ç–µ–ª–æ –ø–∏—Å—å–º–∞.")
            # –ï—Å–ª–∏ —Ç–µ–ª–æ –ø–∏—Å—å–º–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º—ã –ø–æ–¥—Å—Ç–∞–≤–∏–ª–∏ —à–∞–±–ª–æ–Ω),
            # –ø–µ—Ä–µ–¥–∞—ë–º –≤ LLM —Ç–æ–ª—å–∫–æ –µ–≥–æ ‚Äî —á—Ç–æ–±—ã —Ç–µ–º–∞/–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∏—Å—å–º–∞ –Ω–µ –∑–∞–¥–∞–≤–∞–ª–∏ –æ—Ç–≤–µ—Ç.
            if email_text and len(email_text) > 500:
                full_text = email_text
            else:
                full_text = f"–¢–ï–ú–ê: {email_subject}\n–¢–ï–ö–°–¢ –ü–ò–°–¨–ú–ê:\n{email_text}"

        if self.llm_client:
            return self._extract_with_llm(full_text, email_subject)
        else:
            return self._extract_simple(full_text, email_subject)

    def _extract_with_llm(self, text_input: str, email_subject: str) -> Dict:
        """–ó–∞–ø—Ä–æ—Å –∫ LLM —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –≤—ã–≤–æ–¥–∞"""
        # –£–ª—É—á—à—ë–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç: –ø—Ä–æ—Å–∏–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –∏ —è–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–µ
        # `brief_description`, —á—Ç–æ–±—ã –∑–∞—Ç–µ–º –µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Excel.
        prompt = f"""
system
–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ —é—Ä–∏—Å—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –¥–æ–≥–æ–≤–æ—Ä–∞ (–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –∏ –±–µ–∑ —Ç–µ–º—ã –ø–∏—Å—å–º–∞)
–∏ –¥–∞—Ç—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –≤—ã–≤–æ–¥ –æ —Å—É—Ç–∏ –¥–æ–≥–æ–≤–æ—Ä–∞ –≤ 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö (300-600 —Å–∏–º–≤–æ–ª–æ–≤).
–ó–∞—Ö–≤–∞—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏: —Å—Ç–æ—Ä–æ–Ω—ã, –ø—Ä–µ–¥–º–µ—Ç, —Å—É–º–º—É, —Å—Ä–æ–∫–∏, –æ—Å–Ω–æ–≤–Ω—ã–µ —É—Å–ª–æ–≤–∏—è.
–ü–∏—à–∏ –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–¢—Ä–µ–±—É–µ–º—ã–π JSON-—Ñ–æ—Ä–º–∞—Ç (—Å—Ç—Ä–æ–≥–æ):
{{
  "document_type": "(–î–æ–≥–æ–≤–æ—Ä|–ê–∫—Ç|–î–æ–ø.—Å–æ–≥–ª–∞—à–µ–Ω–∏–µ|–î—Ä—É–≥–æ–µ)",
  "brief_description": "(–†–∞–∑–≤—ë—Ä–Ω—É—Ç–æ–µ —Ä–µ–∑—é–º–µ 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –Ω–µ –±–æ–ª–µ–µ 600 —Å–∏–º–≤–æ–ª–æ–≤, –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏)",
  "summary": "(–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)",
  "responsible_person": "(–§–ò–û –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è)",
  "deadline": "(–¥–∞—Ç–∞ –∏–ª–∏ —Å—Ä–æ–∫)",
  "amount": "(—Å—É–º–º–∞ –∏ –≤–∞–ª—é—Ç–∞)"
}}

user
–í–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
<<<
{text_input}
>>>
"""

        try:
            response = self.llm_client(
                prompt,
                max_tokens=800,
                temperature=0.01,
                top_p=0.9,
                echo=False
            )

            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞ –æ—Ç llama_cpp/–æ–±—ë—Ä—Ç–æ–∫
            if isinstance(response, dict) and 'choices' in response:
                result_text = response['choices'][0].get('text', '').strip()
            else:
                result_text = str(response).strip()

            logger.info(f"[DEBUG] Raw LLM output (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤): {result_text[:500]}")
            
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π - —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
            if len(result_text) < 50:
                logger.warning(f"[WARN] LLM output –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π ({len(result_text)} —Å–∏–º–≤): {result_text}")

            # –ü–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å JSON –∏–∑ –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏
            start = result_text.find('{')
            end = result_text.rfind('}')
            if start != -1 and end != -1 and end > start:
                full_json_str = result_text[start:end+1]
            else:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ —Ç–æ–ª—å–∫–æ —Ç–µ–ª–æ –±–µ–∑ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å
                full_json_str = result_text
                if not full_json_str.strip().startswith('{'):
                    full_json_str = '{' + full_json_str
                if not full_json_str.strip().endswith('}'):
                    full_json_str = full_json_str + '}'

            full_json_str = full_json_str.replace('```json', '').replace('```', '').strip()

            # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON; –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî —Ä–æ–±—É—Å—Ç–Ω—ã–π —Ñ–æ–ª–ª–±—ç–∫
            try:
                data = json.loads(full_json_str)
            except Exception as e:
                logger.warning(f"JSON parse failed: {e}. –ü–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç—è–Ω—É—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏.")
                
                data = {}
                
                # –î–æ—Å—Ç–∞—ë–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ raw LLM output –∏—Å–ø–æ–ª—å–∑—É—è regex –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è
                fields_to_extract = {
                    'brief_description': [r'brief_description["\']?\s*[:=]\s*["\']?([^"\']*)["\']?(?:,|$)', 
                                         r'–ö—Ä–∞—Ç–∫(?:–æ–µ)?.*?–æ–ø–∏—Å–∞[–Ω–∏]*–µ\s*[:\-]\s*([^,\n]*)'],
                    'responsible_person': [r'responsible_person["\']?\s*[:=]\s*["\']?([^"\']*)["\']?(?:,|$)',
                                          r'–û—Ç–≤–µ—Å—Ç–≤–µ–Ω–Ω(?:—ã–π|—ã–µ)?\s*[:\-]\s*([^,\n]*)'],
                    'deadline': [r'deadline["\']?\s*[:=]\s*["\']?([^"\']*)["\']?(?:,|$)',
                                r'–°—Ä–æ–∫\s*[:\-]\s*([^,\n]*)'],
                    'amount': [r'amount["\']?\s*[:=]\s*["\']?([^"\']*)["\']?(?:,|$)',
                              r'–°—É–º–º–∞\s*[:\-]\s*([^,\n]*)'],
                    'document_type': [r'document_type["\']?\s*[:=]\s*["\']?([^",\n}]*)', 
                                     r'–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞\s*[:\-]\s*([^,\n]*)']
                }
                
                for field, patterns in fields_to_extract.items():
                    for pattern in patterns:
                        m = re.search(pattern, result_text, re.IGNORECASE | re.DOTALL)
                        if m:
                            val = m.group(1).strip()
                            # –û—á–∏—â–∞–µ–º –æ—Ç –∫–∞–≤—ã—á–µ–∫ –∏ –∑–∞–ø—è—Ç—ã—Ö –≤ –∫–æ–Ω—Ü–µ
                            val = re.sub(r'["\',}\n]*$', '', val).strip()
                            if val and val.lower() not in ['none', 'null', 'string']:
                                data[field] = val
                                break
                
                # FALLBACK: –ï—Å–ª–∏ brief_description –≤—Å—ë –µ—â—ë –Ω–µ –Ω–∞–π–¥–µ–Ω, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                if 'brief_description' not in data or not data.get('brief_description'):
                    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ª–∏–Ω–∏–∏
                    cleaned = re.sub(r'[-]{3,}.*?[-]{3,}', '', result_text, flags=re.IGNORECASE)
                    cleaned = re.sub(r'(–¢–ï–ú–ê|user|system|assistant|JSON)[\s:]*', '', cleaned, flags=re.IGNORECASE)
                    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                    sentences = [s.strip() for s in re.split(r'[.!?]+', cleaned) if s.strip() and len(s.strip()) > 15]
                    if sentences:
                        brief = '. '.join(sentences[:5]).strip() + '.'
                        if len(brief) > 50:
                            data['brief_description'] = brief

            def clean_val(key, default=''):
                val = str(data.get(key, default) or '').strip()
                if val.lower() in ['string', '...', 'null', '', 'none', '—Ç–∏–ø']:
                    return default
                return val

            # –ï—Å–ª–∏ brief_description –ø—É—Å—Ç–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º summary –∏–ª–∏ —á–∞—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            brief = clean_val('brief_description', '')
            if not brief:
                brief = clean_val('summary', '')
            if not brief:
                cleaned_text2 = re.sub(r"---[^\n]*---\s*", "", text_input, flags=re.IGNORECASE)
                brief = cleaned_text2.strip()[:400]

            return {
                'document_type': self._normalize_doc_type(clean_val('document_type', '–î–æ–≥–æ–≤–æ—Ä')),
                'brief_description': brief[:1200],
                'description': clean_val('summary', '')[:2000],
                'responsible_person': clean_val('responsible_person', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                'deadline': clean_val('deadline', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                'amount': clean_val('amount', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ LLM –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return self._extract_simple(text_input, email_subject)

    # --- –ü—Ä–æ—Å—Ç—ã–µ –º–µ—Ç–æ–¥—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ---
    def _extract_simple(self, text: str, subject: str) -> Dict:
        return {
            'document_type': self._detect_document_type(text),
            'description': subject,
            'responsible_person': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å',
            'deadline': self._find_date(text),
            'amount': self._find_amount(text)
        }
        
    def _detect_document_type(self, text: str) -> str:
        text = text.lower()
        if '–¥–æ–≥–æ–≤–æ—Ä' in text: return '–î–æ–≥–æ–≤–æ—Ä'
        if '–∞–∫—Ç' in text: return '–ê–∫—Ç'
        return '–î–æ–∫—É–º–µ–Ω—Ç'

    def _find_date(self, text: str) -> str:
        match = re.search(r'\d{2}[./]\d{2}[./]\d{4}', text)
        return match.group(0) if match else '–ù–µ —É–∫–∞–∑–∞–Ω'

    def _find_amount(self, text: str) -> str:
        match = re.search(r'(\d[\d\s,]*)\s*(—Ä—É–±|—Ç–µ–Ω–≥–µ)', text)
        return match.group(0) if match else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

    def _normalize_doc_type(self, val): return str(val).strip()
    def _clean_person_name(self, val): return str(val).strip()
    def _normalize_date(self, val): return str(val).strip()
    def _normalize_amount(self, val): return str(val).strip()