#!/usr/bin/env python3
"""
Contract Database Analysis Tool
Analyzes 585 contracts: types, parties, amounts, dates, clustering
"""
import os
import json
import csv
from pathlib import Path
from collections import defaultdict
import re
from datetime import datetime

def extract_metadata(filename):
    """Extract likely metadata from filename"""
    metadata = {
        "filename": filename,
        "party": None,
        "type": None,
        "number": None,
        "year": None,
    }
    
    # Extract contract number (‚ÑñXX pattern)
    number_match = re.search(r'‚Ññ(\d+)', filename)
    if number_match:
        metadata["number"] = number_match.group(1)
    
    # Extract year (20XX pattern)
    year_match = re.search(r'(20\d{2})', filename)
    if year_match:
        metadata["year"] = year_match.group(1)
    
    # Identify contract type by keywords
    filename_lower = filename.lower()
    
    contract_types = {
        "–î–æ–≥–æ–≤–æ—Ä": ["–¥–æ–≥–æ–≤–æ—Ä"],
        "–î–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": ["–¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"],
        "–ê—Ä–µ–Ω–¥–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ": ["–∞—Ä–µ–Ω–¥–∞"],
        "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ": ["–¥–æ–ø", "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª"],
        "–ü—Ä–∏–∫–∞–∑": ["–ø—Ä–∏–∫–∞–∑"],
        "–ü–∏—Å—å–º–æ": ["–ø–∏—Å—å–º–æ", "pismo"],
        "–ê–∫—Ç": ["–∞–∫—Ç"],
        "–†–µ—à–µ–Ω–∏–µ": ["—Ä–µ—à–µ–Ω–∏–µ"],
        "–ü—Ä–æ—Ç–æ–∫–æ–ª": ["–ø—Ä–æ—Ç–æ–∫–æ–ª"],
        "–†–∞—Å–ø–∏—Å–∫–∞": ["—Ä–∞—Å–ø–∏—Å–∫–∞"],
        "–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è": ["—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü"],
    }
    
    for contract_type, keywords in contract_types.items():
        if any(kw in filename_lower for kw in keywords):
            metadata["type"] = contract_type
            break
    
    # Extract party name (common organization names)
    parties = [
        "–°–î–°", "–ê–º–∞–Ω–∞—Ç", "–ö–æ–º—Ñ–æ—Ä—Ç", "–ê–∫–±–∞—Ä—ã—Å", "–ë–ò–û–°",
        "–ê–ª—Ç—ã–Ω", "–ê–∑–∞—Ç", "–ê–∫—Ç–æ–±–µ", "–†–æ—Å—Ç", "–ö–æ–ø—Ç–ª–µ—É–æ–≤",
        "–ú–∞—Ö–∞—Ç–æ–≤", "–ù–∞–≥–∞—É–æ–≤", "–¢–ö–ê", "–ê–ú–ö", "–°—Ç—Ä–æ–Ω–µ—Ñ",
        "–î—Ä–æ–∑–¥–æ–≤", "–û—â–µ–ø–∫–æ–≤", "–°–∞–¥–∂–∞—Ä", "–ú–∞–º—ã—Ä", "–®–∞–≥—Ä–æ–≤",
    ]
    
    for party in parties:
        if party in filename:
            metadata["party"] = party
            break
    
    return metadata

def classify_contract(filename):
    """Classify contract by type"""
    filename_lower = filename.lower()
    
    if any(x in filename_lower for x in ["–∞—Ä–µ–Ω–¥–∞", "–∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä", "arenda"]):
        return "–ê—Ä–µ–Ω–¥–∞/Lease"
    elif any(x in filename_lower for x in ["–¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"]):
        return "–î–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å/Power of Attorney"
    elif any(x in filename_lower for x in ["–ø–æ—Å—Ç–∞–≤–∫–∞", "–ø—Ä–æ–¥–∞–∂–∞", "–∫—É–ø–ª—è"]):
        return "–ü–æ–∫—É–ø–∫–∞-–ø—Ä–æ–¥–∞–∂–∞/Supply"
    elif any(x in filename_lower for x in ["–ø–æ–¥—Ä—è–¥", "—Å—Ç—Ä–æ–∏", "–º–æ–Ω—Ç–∞–∂", "–æ—Ç–¥–µ–ª–∫–∞", "–¥–µ–º–æ–Ω—Ç–∞–∂"]):
        return "–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ/Construction"
    elif any(x in filename_lower for x in ["—É—Å–ª—É–≥", "–æ–±—Å–ª—É–∂", "—Å–µ—Ä–≤–∏—Å", "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"]):
        return "–£—Å–ª—É–≥–∏/Services"
    elif any(x in filename_lower for x in ["–¥–æ–ø —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ", "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª"]):
        return "–î–æ–ø. —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ/Amendment"
    elif any(x in filename_lower for x in ["–ø—Ä–∏–∫–∞–∑"]):
        return "–ü—Ä–∏–∫–∞–∑/Order"
    elif any(x in filename_lower for x in ["–ø–∏—Å—å–º–æ", "pismo"]):
        return "–ü–∏—Å—å–º–æ/Letter"
    elif any(x in filename_lower for x in ["–∞–∫—Ç", "–ø—Ä–∏–µ–º–∫–∞"]):
        return "–ê–∫—Ç/Act"
    else:
        return "–î—Ä—É–≥–æ–µ/Other"

def analyze_templates_directory():
    """Analyze all contracts in templates directory"""
    templates_dir = Path("templates")
    
    if not templates_dir.exists():
        print("‚ùå templates directory not found")
        return
    
    print("=" * 70)
    print("CONTRACT DATABASE ANALYSIS")
    print("=" * 70)
    
    # Collect statistics
    files = list(templates_dir.glob("*"))
    total_files = len(files)
    
    # File types
    file_types = defaultdict(int)
    file_sizes = defaultdict(int)
    
    # Contract classification
    contract_types = defaultdict(int)
    
    # Parties
    parties = defaultdict(int)
    
    # Years
    years = defaultdict(int)
    
    # Numbers
    numbers_set = set()
    
    # Metadata
    all_metadata = []
    
    print(f"\nAnalyzing {total_files} contracts...")
    
    for file_path in files:
        if file_path.is_file():
            # File type
            ext = file_path.suffix.lower()
            file_types[ext] += 1
            file_sizes[ext] += file_path.stat().st_size
            
            # Classification
            contract_type = classify_contract(file_path.name)
            contract_types[contract_type] += 1
            
            # Metadata
            metadata = extract_metadata(file_path.name)
            metadata["ext"] = ext
            metadata["size_kb"] = file_path.stat().st_size / 1024
            metadata["contract_type"] = contract_type
            
            all_metadata.append(metadata)
            
            if metadata["party"]:
                parties[metadata["party"]] += 1
            
            if metadata["year"]:
                years[metadata["year"]] += 1
            
            if metadata["number"]:
                numbers_set.add(int(metadata["number"]))
    
    # ===== PRINT RESULTS =====
    
    print(f"\n‚úì TOTAL CONTRACTS: {total_files}")
    
    print("\nüìÅ FILE TYPES:")
    for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):
        size_mb = file_sizes[ext] / (1024 * 1024)
        percentage = (count / total_files) * 100
        print(f"  {ext:<6} {count:>4} files ({percentage:>5.1f}%) - {size_mb:>6.1f} MB")
    
    total_size_mb = sum(file_sizes.values()) / (1024 * 1024)
    print(f"\n  Total size: {total_size_mb:.1f} MB")
    
    print("\nüìã CONTRACT TYPES:")
    for contract_type, count in sorted(contract_types.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_files) * 100
        print(f"  {contract_type:<40} {count:>4} ({percentage:>5.1f}%)")
    
    print("\nüë• TOP PARTIES (Organizations/Individuals):")
    top_parties = sorted(parties.items(), key=lambda x: x[1], reverse=True)[:15]
    for party, count in top_parties:
        percentage = (count / total_files) * 100
        print(f"  {party:<30} {count:>4} contracts ({percentage:>5.1f}%)")
    
    if len(parties) > 15:
        print(f"  ... and {len(parties) - 15} more parties")
    
    print("\nüìÖ CONTRACTS BY YEAR:")
    for year in sorted(years.keys()):
        count = years[year]
        percentage = (count / total_files) * 100
        print(f"  {year}: {count:>4} contracts ({percentage:>5.1f}%)")
    
    if numbers_set:
        print(f"\nüî¢ CONTRACT NUMBERS:")
        print(f"  Range: {min(numbers_set)} - {max(numbers_set)}")
        print(f"  Count with numbers: {len(numbers_set)}")
    
    # Save detailed CSV
    print(f"\nüíæ Saving detailed analysis...")
    csv_file = "contract_analysis.csv"
    with open(csv_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=all_metadata[0].keys())
        writer.writeheader()
        writer.writerows(all_metadata)
    print(f"  ‚úì {csv_file} ({len(all_metadata)} records)")
    
    # Save JSON summary
    summary = {
        "analysis_date": datetime.now().isoformat(),
        "total_contracts": total_files,
        "total_size_mb": round(total_size_mb, 2),
        "file_types": dict(file_types),
        "contract_types": dict(contract_types),
        "top_parties": dict(top_parties),
        "years": dict(sorted(years.items())),
        "unique_numbers": len(numbers_set),
        "unique_parties": len(parties),
    }
    
    json_file = "contract_analysis.json"
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    print(f"  ‚úì {json_file}")
    
    # Save contracts by type
    contracts_by_type = defaultdict(list)
    for metadata in all_metadata:
        contracts_by_type[metadata["contract_type"]].append(metadata["filename"])
    
    type_file = "contracts_by_type.json"
    with open(type_file, "w", encoding="utf-8") as f:
        json.dump(dict(contracts_by_type), f, indent=2, ensure_ascii=False)
    print(f"  ‚úì {type_file}")
    
    print("\n" + "=" * 70)
    print("‚úÖ ANALYSIS COMPLETE")
    print("=" * 70)
    
    print("\nFiles generated:")
    print(f"  1. {csv_file} - Full details for all contracts")
    print(f"  2. {json_file} - Summary statistics")
    print(f"  3. {type_file} - Contracts organized by type")
    
    print("\nNext steps:")
    print("  1. python main.py --index-templates (index into RAG)")
    print("  2. python main.py --test --rag (test semantic search)")
    print("  3. python main.py --stats (show RAG statistics)")

if __name__ == "__main__":
    analyze_templates_directory()
